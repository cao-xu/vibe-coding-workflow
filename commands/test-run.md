---
description: 测试执行（运行测试脚本、分析结果、修复重测、更新文档）
allowed-tools: Read(*), Write(*), Bash(*)
argument-hint: [功能模块名 kebab-case，如 user-auth]
model: opus
---

> **环境兼容说明：** 本文档中的 `CLAUDE.md / AGENTS.md` 指项目根目录下的 AI 记忆文件。
> - Claude Code → `CLAUDE.md`
> - OpenAI Codex → `AGENTS.md`
> 请根据你所在的环境使用对应的文件。

## AI 角色定位

- 🧪 **测试执行者**：运行测试脚本，收集结果
- 📊 **结果分析者**：分析失败原因，提供修复建议
- 📝 **文档更新者**：记录测试结果到 test_design.md，按需更新 todo.md 进度

## AI 执行原则

### 原则 1：如实报告

- 测试结果如实报告，不隐藏失败
- 失败原因要分析到具体代码位置
- 不确定的问题标注"需要工程师确认"

### 原则 2：问题分类处理

| 问题类型 | AI 的处理方式 |
|----------|--------------|
| 明确的代码 Bug | 定位问题，提供修复建议 |
| 测试脚本问题 | 分析原因，建议调整测试 |
| 环境配置问题 | 列出检查项，请工程师确认 |
| 不确定的问题 | 标注"需要工程师判断" |

---

# AI 工作流程

## Step 0: 确认执行条件

在执行测试前，AI 必须确认：

```
## 测试执行前检查

### 文档就绪
- [ ] `docs/features/<feature-name>/test_design.md` 存在
- [ ] `tests/e2e/test_<feature_name>.sh` 存在
- [ ] `tests/regression/test_regression_<feature_name>.sh` 存在

### 环境就绪
- [ ] 服务已启动（请工程师确认）
- [ ] 环境变量已配置（.env）
- [ ] 依赖服务可用（数据库、缓存等）

**请工程师确认以上条件是否满足？**
```

**功能模块名称从 $ARGUMENTS 获取，如果未提供，必须先询问我。**

**等待工程师确认后再执行测试。**

---

## Step 1: 阅读测试设计

执行前必须阅读：

1. **`test_design.md`**：理解测试策略和预期结果
2. **测试脚本**：了解具体的测试步骤
3. **`CLAUDE.md / AGENTS.md`**：了解测试基础设施的使用方法

---

## Step 2: 执行测试

### 2.1 执行顺序

按以下顺序执行测试：

```
1. 单元测试（如果有）
       ↓
2. 功能测试（E2E）
       ↓
3. 回归测试
```

### 2.2 执行方式

```
# 1. 执行功能测试
chmod +x tests/e2e/test_<feature_name>.sh
./tests/e2e/test_<feature_name>.sh

# 2. 执行回归测试
chmod +x tests/regression/test_regression_<feature_name>.sh
./tests/regression/test_regression_<feature_name>.sh
```

### 2.3 记录执行过程

```
## 测试执行记录

### 功能测试（E2E）
- 脚本：`tests/e2e/test_<feature_name>.sh`
- 开始时间：[时间]
- 结束时间：[时间]
- 结果：[通过 / 失败]

### 回归测试
- 脚本：`tests/regression/test_regression_<feature_name>.sh`
- 开始时间：[时间]
- 结束时间：[时间]
- 结果：[通过 / 失败]
```

---

## Step 3: 分析测试结果

### 3.1 如果全部通过

```
## ✅ 测试全部通过

### 执行摘要
- 功能测试：✅ 通过
- 回归测试：✅ 通过

### 下一步
可以进入**代码评审**环节。
```

### 3.2 如果有失败

```
## ❌ 测试存在失败

### 执行摘要
- 功能测试：[✅ 通过 / ❌ 失败]
- 回归测试：[✅ 通过 / ❌ 失败]

### 失败详情

#### 失败 1：[测试名称]
- **错误信息：** [具体错误]
- **问题分类：** [代码 Bug / 测试脚本问题 / 环境问题 / 需要工程师判断]
- **定位分析：** [分析问题原因，定位到具体代码]
- **修复建议：** [具体的修复方案]

#### 失败 2：[测试名称]
...

### 处理建议

请工程师选择处理方式：
1. **修复代码**：按上述建议修复后重新测试
2. **调整测试**：如果测试用例设计有问题，调整测试脚本
3. **接受风险**：如果是已知限制，记录风险后继续
```

---

## Step 4: 问题修复与重测（如果需要）

### 4.1 如果工程师选择修复代码

```
## 修复后重测

### 修复内容
- 文件：`path/to/file.py`
- 改动：[描述修复内容]

### 重新执行测试
[执行测试脚本，记录结果]

### 结果
- [✅ 通过 / ❌ 仍然失败]
```

### 4.2 如果工程师选择调整测试

```
## 测试调整

### 调整原因
[说明为什么需要调整测试]

### 调整内容
- 文件：`tests/e2e/test_<feature_name>.sh`
- 改动：[描述调整内容]

### 重新执行测试
[执行测试脚本，记录结果]
```

---

## Step 5: 更新文档

测试完成后，更新相关文档：

### 5.1 更新 test_design.md 执行日志

```
## 执行日志

### [日期] 测试执行记录

#### 执行环境
- 服务版本：[版本/commit]
- 执行人：[工程师名]

#### 执行结果
| 测试类型 | 脚本 | 结果 | 耗时 |
|----------|------|------|------|
| 功能测试 | test_<feature>.sh | ✅/❌ | [x]s |
| 回归测试 | test_regression_<feature>.sh | ✅/❌ | [x]s |

#### 问题记录（如果有）
- [问题1]：[处理方式]

#### 结论
[测试通过，可以进入代码评审 / 需要继续修复]
```

### 5.2 更新 todo.md 进度（按需）

如果测试通过，更新 todo.md 中的测试任务状态：

```
## 待办
### 测试
- [x] 功能测试 ✅ [日期]
- [x] 回归测试 ✅ [日期]

## 进度
- 阶段：测试通过，待代码评审
```

---

## Step 6: 经验沉淀（按需）

如果在测试过程中发现了**高复用价值**的经验，沉淀到 `CLAUDE.md / AGENTS.md`：

### 沉淀检查
- [ ] 这个经验会在其他功能测试中遇到吗？
- [ ] 6个月后做类似测试时，这条信息还有用吗？

### 沉淀格式（如果需要）

```
## 测试执行经验：<feature-name>

### 踩坑记录
- [坑]：[解决方案]（一句话）

### 测试技巧
- [技巧]：[适用场景]
```

---

# 输出格式汇总

## 测试开始
```
## 🧪 开始测试执行

### 功能模块
[feature-name]

### 测试脚本
- 功能测试：`tests/e2e/test_<feature_name>.sh`
- 回归测试：`tests/regression/test_regression_<feature_name>.sh`

### 执行条件确认
请工程师确认：
- [ ] 服务已启动
- [ ] 环境配置正确
```

## 测试进行中
```
## 📊 测试执行中

### 功能测试
🔄 正在执行...
[实时输出测试结果]

### 回归测试
⏳ 等待执行
```

## 测试完成
```
## ✅ / ❌ 测试执行完成

### 结果摘要
- 功能测试：[结果]
- 回归测试：[结果]

### 下一步
[根据结果给出建议]
```

---

# 职责边界总结

## AI 的职责
- ✅ 执行测试脚本，收集结果
- ✅ 分析失败原因，提供修复建议
- ✅ 更新 test_design.md（执行日志）
- ✅ 更新 todo.md（测试进度）
- ❌ 不要隐藏测试失败

## 工程师的职责
- ✅ 确保服务和环境就绪
- ✅ 决策失败的处理方式
- ✅ 决定是否进入代码评审

---

# 与工作流的衔接

```
1. 需求分析与评审
       ↓
2. 开发方案设计 → todo.md, design.md
       ↓
3. 开发方案评审（非必须，独立上下文）
       ↓
4. 测试方案设计 → test_design.md
       ↓
5. 测试方案评审（非必须，独立上下文）
       ↓
6. 测试基础设施准备（非必须）
       ↓
7. 开发执行 → 代码实现
       ↓
8. 【测试执行】← 当前环节（90% 时间占比）
       ↓
9. 代码评审（双模型，独立上下文）
       ↓
10. 文档整理 → change log + 知识库更新
```

**输入：**
- `test_design.md`（测试策略和场景）
- `tests/e2e/test_<feature_name>.sh`（功能测试脚本）
- `tests/regression/test_regression_<feature_name>.sh`（回归测试脚本）
- 已完成的代码实现

**输出：**
- 测试执行结果
- 更新后的 `test_design.md`（含执行日志）
- 问题修复记录（如果有）

---

# 扩展规则（持续更新）

## 测试执行约定
-

## 环境配置要求
-

## 特殊场景处理
-
